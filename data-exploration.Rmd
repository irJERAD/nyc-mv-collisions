---
title: "NYC Open Data Exploration"
output: html_notebook
---

# About

This notebook explores the more recent data from NYC Open Data [Data Set](https://data.cityofnewyork.us/Public-Safety/NYPD-Motor-Vehicle-Collisions/h9gi-nx95).

This dataset can also be reached and interacted with through its [Google BigQuery location](https://bigquery.cloud.google.com/table/bigquery-public-data:new_york.nypd_mv_collisions?tab=schema)

## Exercise Overview

For this exercise, we'd like you to analyze data on New York motor vehicle collisions and answer the following question:    
**What are your ideas for reducing accidents in Brooklyn?**   
Imagine you are preparing this presentation for the city council who will use it to inform new legislation and/or projects.

### TODO

Briefly:  

1. Inspect dataset  
2. Identify dependent / outcome variables  
3. iterate over:  
    a. hypothesize predictor variables  
    b. test  
    c. document & consider results  
  
      
- Setup   
    + [ ] Libraries (_continual_)  
    + [x] data  
- Understand
    + [x] structure  
    + [x] summary  
    + [ ] identify dependent variables  

## Setup

### Load Libraries

Libraries that will be used during exploration
```{r libraries}
library(magrittr)
library(dplyr)
```

### Load Data

Load data from /data directory and into memory
```{r import-data, cache=TRUE}
dt <- read.csv(file = "data/NYPD_Motor_Vehicle_Collisions.csv")
```

## Undertand Dataset

### Dataset Structure

Inspect structure of dataset with the `str()` command:
```{r data-structure}
str(dt)
```

### Dataset Summary

Inspect summary of dataset with `summary()` command:
```{r data-summary}
summary(dt)
```


### Dataset Variables

Our Dataset structure revealed the variables and their classes `sapply(names(dt), function(x) paste0(x, ' is class: ', class(dt[[x]])))`= `r sapply(names(dt), function(x) paste0('<br>','<b>',x,'</b>','<em>',' is class: ','</em>','<u>',class(dt[[x]]),'</u>'))`

### Understanding Conclusion  

With a goal of _reducing accidents in Brooklyn_ our main goal is to reduce observations of accidents where `BOROUGH == "BROOKLYN"`.  

#### Proposed Solutions:  

- Explore facets of variables  
    + Datetime  
        + Time of day  
        + Day of week
        + Day of month
        + Day or Month of year
- Explore trends `group_by`  
    + Across time  
    + Across space
        + Burrough
        + Zip
        + Street Name (On, Cross, Off)
    + Across Vehicle Type


**1. Subset:**
If we look at the subset of the dataset where BOROUGH is "BROOKLYN" `brooklyn <- filter(dt, BOROUGH == "BROOKLYN")` we want to find patterns in the existing observations and propose methods to eliminate these patterns.     

- There are `length(levels(dt$BOROUGH))`: `r length(levels(dt$BOROUGH))` levels in the factor variable `BOROUGH`  
- Including `levels(dt$BOROUGH)`: `r levels(dt$BOROUGH)`.  
- So we really have 5 defined Boroughs, Brooklyn being one of which, with the 6th being an `NA` or blank value.  
- Subsetting to Brooklyn gives us 223552 observations, reducing set of observations by over 75%  

- Explore facets of variables  
    + Datetime  
        + Time of day  
        + Day of week
        + Day of month
        + Day or Month of year
- Explore trends  
    + Across time

**2. Other Success (_over time_):**
Look for reductions in other burroughs over time and propose similar efforts.



## Exploration

### Subset to Brooklyn

Create subset of Brooklyn observations:
```{r filter-brooklyn}
brooklyn <- filter(dt, BOROUGH == "BROOKLYN")
```

### Look at CONTRIBUTING.FACTOR.*

```{r fact-1}
fact.1 <- brooklyn %>%
  group_by(CONTRIBUTING.FACTOR.VEHICLE.1) %>%
  tally(sort = TRUE)
fact.1
```

Only 3 factor levels appear over 10,000 times in the `brooklyn$CONTRIBUTING.FACTOR.VEHICLE.1` variable.

#### Distribution of CONTRIBUTING.FACTOR.VEHICLE.1

Explore quantile distribution of `brooklyn$CONTRIBUTING.FACTOR.VEHICLE.1` variable then use cumulative distribution to calculate the probability / percentage of factor levels below 10,000 and 5,000
```{r fact-dist}
quantile(fact.1$n)
ecdf(fact.1$n)(10000)
ecdf(fact.1$n)(5000)
```

An expected majority of `ecdf(fact.1$n)(10000)` = `r ecdf(fact.1$n)(10000) * 100`% are below 10,000 occurances.  
Of interest is still nearly 90% below 5,000 which also provides us double the defined contributing factors (since the largest observation is listed as "Unspecified")